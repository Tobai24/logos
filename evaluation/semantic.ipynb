{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import minsearch\n",
    "import openai\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings using pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/practice/logos/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"documents_with_ids.json\", 'r') as f_in:\n",
    "    documents_id = json.load(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup ElasticSearch connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '37b2288c9e17', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'srJ-aaLQQHCyqLZPfWZkpw', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mappings and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'vector_db'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": { \n",
    "        \"properties\": {\n",
    "            # Fields for Bible verses\n",
    "            \"book\": { \"type\": \"text\" },  # Bible-specific field\n",
    "            \"book_name\": { \"type\": \"keyword\" },  # Bible-specific field\n",
    "            \"chapter\": { \"type\": \"text\" },  # Bible-specific field\n",
    "            \"verse\": { \"type\": \"text\" },  # Bible-specific field\n",
    "            \n",
    "            # Fields for YouTube transcripts\n",
    "            \"video_id\": { \"type\": \"keyword\" },  # Video-specific field\n",
    "            \"title\": { \"type\": \"text\" },  # Video-specific field\n",
    "            \"publish_date\": { \"type\": \"date\" },  # Video-specific field\n",
    "            \"author\": { \"type\": \"text\" },  # Video-specific field\n",
    "\n",
    "            # Common field for both types of documents\n",
    "            \"text\": { \"type\": \"text\" },  # Both Bible verses and video transcripts share this\n",
    "            \"text_vector\": {\"type\": \"dense_vector\", \"dims\": 768, \"index\": True, \"similarity\": \"cosine\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"vector_db\"\n",
    "\n",
    "# Create the index\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add documents into index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9163ce76eb46a4a67b22d13aae5589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36755 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents_id):\n",
    "    text = doc['text']\n",
    "\n",
    "    doc['text_vector'] = model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15aae4636e34cb1994227ae00e3cb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36755 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents_id):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create end user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"who is daniel\"\n",
    "vector_search_term = model.encode(search_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the evaluation metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(question_dict, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(questions_dict):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the questions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "questions = pd.read_csv('questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dict = questions.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(question_dict, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(questions_dict):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(es_client, index_name, embedding_vector):\n",
    "    # Construct the search query\n",
    "    search_query = {\n",
    "        \"size\": 10,  # Limit the number of results\n",
    "        \"knn\": {\n",
    "            \"field\": \"text_vector\",  # Field containing the dense vector\n",
    "            \"query_vector\": embedding_vector,  # The query vector (embedding)\n",
    "            \"k\": 10,  # Number of nearest neighbors to retrieve\n",
    "            \"num_candidates\": 1000  # Candidate pool size for efficiency\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Execute the search query\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    # Collect and return the results from the hits\n",
    "    result_docs = [hit['_source'] for hit in response['hits']['hits']]\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_vector_knn(q):\n",
    "    question = q['question']\n",
    "\n",
    "    embedding_vector = model.encode(question)\n",
    "\n",
    "    return semantic_search(es_client, index_name, embedding_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ae88cfcfb649eaa63694dad50063b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.25327272727272726, 'mrr': 0.1530637085137085}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(questions_dict, question_vector_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrival with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from typing import Dict\n",
    "from langchain_elasticsearch import ElasticsearchRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_url = 'http://localhost:9200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89553/3980012484.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
      "/root/practice/logos/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"who is john chapter 1 vs 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_hybrid(query):\n",
    "    def hybrid_query(search_query: str) -> Dict:\n",
    "        # Generate the embedding vector for the query\n",
    "        embedding_vector = embeddings.embed_query(search_query)\n",
    "    \n",
    "        return {\n",
    "            \"size\": 5,  # Limit the number of results\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    # Keyword-based search\n",
    "                    \"must\": {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": search_query,\n",
    "                            \"fields\": [\"text^4\", \"book_name\", \"chapter\", \"verse\", \"title\", \"author\"],  # Bible and video fields\n",
    "                            \"type\": \"best_fields\",\n",
    "                            \"boost\": 0.5\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            # Semantic search using k-nearest neighbors (KNN)\n",
    "            \"knn\": {\n",
    "                \"field\": \"text_vector\",  # Field that stores the dense vectors for semantic search\n",
    "                \"query_vector\": embedding_vector,  # The query vector (embedding)\n",
    "                \"k\": 5,  # Number of nearest neighbors to retrieve\n",
    "                \"num_candidates\": 10000,  # Number of candidate vectors to consider for efficiency\n",
    "                \"boost\": 0.5,  # Adjust the weight of vector similarity\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Elasticsearch retriever initialization\n",
    "    hybrid_retriever = ElasticsearchRetriever.from_es_params(\n",
    "        index_name=index_name,\n",
    "        body_func=hybrid_query,\n",
    "        content_field='text',  # The field to retrieve text content from\n",
    "        url=es_url,  # The Elasticsearch URL endpoint\n",
    "    )\n",
    "    hybrid_results = hybrid_retriever.invoke(query)\n",
    "\n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in hybrid_results:\n",
    "        result_docs.append(hit.metadata['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_results = hybrid_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hybrid search evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_text_hybrid(q):\n",
    "    question = q['question']\n",
    "\n",
    "    return elastic_search_hybrid(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c5cd3487a54ea6b219fd278b471934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.11018181818181819, 'mrr': 0.0825818181818181}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(questions_dict, question_text_hybrid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
